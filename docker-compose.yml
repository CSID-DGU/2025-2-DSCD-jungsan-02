version: '3.8'

services:
  flask-app:
    image: jang99u/lostfound-flask:latest
    container_name: flask-app
    ports:
      - "5001:5001"
    gpus: all
    environment:
      CAPTION_MODEL_ID: "Qwen/Qwen2.5-VL-7B-Instruct"
      EMBEDDING_MODEL_NAME: "BAAI/bge-m3"
      EMBEDDING_DIMENSION: "1024"
      FAISS_STORAGE_DIR: "/app/faiss-data"
      GUNICORN_WORKERS: "1"  # GPU 메모리 제한으로 1개 워커만 사용 (각 워커가 독립적으로 모델 로드)
      # HuggingFace 모델 캐시를 볼륨으로 마운트하여 컨테이너 내부 디스크 공간 절약
      HF_HOME: "/app/hf-cache"
      TRANSFORMERS_CACHE: "/app/hf-cache"
      HF_HUB_CACHE: "/app/hf-cache"
      # PyTorch 메모리 할당 최적화 (메모리 파편화 감소)
      PYTORCH_CUDA_ALLOC_CONF: "expandable_segments:True"
      # CUDA 메모리 할당 전략
      CUDA_LAUNCH_BLOCKING: "0"  # 비동기 실행으로 성능 향상 
    volumes:
      # 절대 경로 사용으로 변경 (볼륨 마운트 안정성 향상)
      - /home/mj/lostfound/faiss-data:/app/faiss-data
      - /home/mj/lostfound/hf-cache:/app/hf-cache  # HuggingFace 모델 캐시를 호스트에 저장하여 컨테이너 내부 공간 절약
    networks:
      - backend

  spring-app:
    image: jang99u/lostfound-spring:latest
    container_name: spring-app
    depends_on:
      - flask-app
    ports:
      - "8080:8080"
    volumes:
      - /home/mj:/data  # 호스트의 /home/mj를 컨테이너의 /data로 마운트
    networks:
      - backend

networks:
  backend:
